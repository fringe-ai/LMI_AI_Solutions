<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">anomaly_detectors_v0_packaged.html</title>
      <link href="assets/style.css" rel="stylesheet" type="text/css"/>
  </head>
  <body>
    <h1 id="title">anomaly_detectors_v0_packaged.html</h1>
    <p>Report generated on 27-Jan-2025 at 20:31:10 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</th>
        </tr>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left"><</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">></div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">3 tests took 00:02:07.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to get the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" disabled/>
            <span class="failed">0 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" />
            <span class="passed">3 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" disabled/>
            <span class="skipped">0 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" disabled/>
            <span class="xfailed">0 Expected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled/>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" disabled/>
            <span class="error">0 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled/>
            <span class="rerun">0 Reruns</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  </body>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.10.12&#34;, &#34;Platform&#34;: &#34;Linux-6.8.0-51-generic-x86_64-with-glibc2.35&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;8.1.1&#34;, &#34;pluggy&#34;: &#34;1.4.0&#34;}, &#34;Plugins&#34;: {&#34;hydra-core&#34;: &#34;1.3.2&#34;, &#34;html&#34;: &#34;4.1.1&#34;, &#34;metadata&#34;: &#34;3.1.1&#34;, &#34;xdoctest&#34;: &#34;1.0.2&#34;, &#34;rerunfailures&#34;: &#34;14.0&#34;, &#34;hypothesis&#34;: &#34;5.35.1&#34;, &#34;xdist&#34;: &#34;3.5.0&#34;, &#34;flakefinder&#34;: &#34;1.1.0&#34;, &#34;shard&#34;: &#34;0.1.2&#34;}}, &#34;tests&#34;: {&#34;tests/anomaly_detectors/anomalib_lmi/test_anomaly_model.py::test_model&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/anomaly_detectors/anomalib_lmi/test_anomaly_model.py::test_model&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/anomaly_detectors/anomalib_lmi/test_anomaly_model.py::test_model&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;---------------------------- Captured stderr setup -----------------------------\nINFO:test_anomaly_model:Skipping adding root path to sys.path\n\n------------------------------ Captured log setup ------------------------------\nINFO     test_anomaly_model:test_anomaly_model.py:20 Skipping adding root path to sys.path\n\n----------------------------- Captured stderr call -----------------------------\nINFO:AnomalyModel v0:Loading model: tests/assets/models/ad/model_v0.pt\nINFO:AnomalyModel v0:8 images from tests/assets/images/nvtec-ad\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/004-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/001-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/002-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/003-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/003-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/000-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/002-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/001-bad.png.\nINFO:AnomalyModel v0:Computing anomaly score PDF for all data.\nINFO:AnomalyModel v0:Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\nINFO:AnomalyModel v0:Anomaly patch threshold for 50% patch failure rate:7.933134044930409\nINFO:AnomalyModel v0:Anomaly max set to 97 percentile:42.51430235990022\nINFO:AnomalyModel v0:Min Proc Time: 0.024661540985107422\nINFO:AnomalyModel v0:Max Proc Time: 0.245941162109375\nINFO:AnomalyModel v0:Avg Proc Time: 0.053558170795440674\nINFO:AnomalyModel v0:Median Proc Time: 0.026253581047058105\nINFO:AnomalyModel v0:Test results saved to tests/assets/validation/ad_v0\nINFO:AnomalyModel v0:Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n\n------------------------------ Captured log call -------------------------------\nINFO     AnomalyModel v0:anomaly_model.py:44 Loading model: tests/assets/models/ad/model_v0.pt\nINFO     AnomalyModel v0:base.py:253 8 images from tests/assets/images/nvtec-ad\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/004-bad.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/001-good.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/002-bad.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/003-bad.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/003-good.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/000-bad.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/002-good.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/001-bad.png.\nINFO     AnomalyModel v0:base.py:282 Computing anomaly score PDF for all data.\nINFO     AnomalyModel v0:base.py:324 Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\nINFO     AnomalyModel v0:base.py:329 Anomaly patch threshold for 50% patch failure rate:7.933134044930409\nINFO     AnomalyModel v0:base.py:338 Anomaly max set to 97 percentile:42.51430235990022\nINFO     AnomalyModel v0:base.py:369 Min Proc Time: 0.024661540985107422\nINFO     AnomalyModel v0:base.py:370 Max Proc Time: 0.245941162109375\nINFO     AnomalyModel v0:base.py:371 Avg Proc Time: 0.053558170795440674\nINFO     AnomalyModel v0:base.py:372 Median Proc Time: 0.026253581047058105\nINFO     AnomalyModel v0:base.py:373 Test results saved to tests/assets/validation/ad_v0\nINFO     AnomalyModel v0:base.py:376 Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n\n&#34;}], &#34;tests/anomaly_detectors/anomalib_lmi/test_anomaly_model.py::test_model_api&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/anomaly_detectors/anomalib_lmi/test_anomaly_model.py::test_model_api&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/anomaly_detectors/anomalib_lmi/test_anomaly_model.py::test_model_api&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;---------------------------- Captured stderr setup -----------------------------\nINFO:test_anomaly_model:Skipping adding root path to sys.path\n\n------------------------------ Captured log setup ------------------------------\nINFO     test_anomaly_model:test_anomaly_model.py:20 Skipping adding root path to sys.path\n\n----------------------------- Captured stderr call -----------------------------\nINFO:AnomalyModel v0:Loading model: tests/assets/models/ad/model_v0.pt\nINFO:AnomalyModel v0:8 images from tests/assets/images/nvtec-ad\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/004-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/001-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/002-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/003-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/003-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/000-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/002-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/001-bad.png.\nINFO:AnomalyModel v0:Computing anomaly score PDF for all data.\nINFO:AnomalyModel v0:Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\nINFO:AnomalyModel v0:Anomaly patch threshold for 50% patch failure rate:7.933134044930409\nINFO:AnomalyModel v0:Anomaly max set to 97 percentile:42.51430235990022\nINFO:AnomalyModel v0:Min Proc Time: 0.024167776107788086\nINFO:AnomalyModel v0:Max Proc Time: 0.025732994079589844\nINFO:AnomalyModel v0:Avg Proc Time: 0.02517560124397278\nINFO:AnomalyModel v0:Median Proc Time: 0.02549576759338379\nINFO:AnomalyModel v0:Test results saved to tests/assets/validation/ad_v0\nINFO:AnomalyModel v0:Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n\n------------------------------ Captured log call -------------------------------\nINFO     AnomalyModel v0:anomaly_model.py:44 Loading model: tests/assets/models/ad/model_v0.pt\nINFO     AnomalyModel v0:base.py:253 8 images from tests/assets/images/nvtec-ad\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/004-bad.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/001-good.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/002-bad.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/003-bad.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/003-good.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/000-bad.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/002-good.png.\nINFO     AnomalyModel v0:base.py:265 Processing image: tests/assets/images/nvtec-ad/001-bad.png.\nINFO     AnomalyModel v0:base.py:282 Computing anomaly score PDF for all data.\nINFO     AnomalyModel v0:base.py:324 Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\nINFO     AnomalyModel v0:base.py:329 Anomaly patch threshold for 50% patch failure rate:7.933134044930409\nINFO     AnomalyModel v0:base.py:338 Anomaly max set to 97 percentile:42.51430235990022\nINFO     AnomalyModel v0:base.py:369 Min Proc Time: 0.024167776107788086\nINFO     AnomalyModel v0:base.py:370 Max Proc Time: 0.025732994079589844\nINFO     AnomalyModel v0:base.py:371 Avg Proc Time: 0.02517560124397278\nINFO     AnomalyModel v0:base.py:372 Median Proc Time: 0.02549576759338379\nINFO     AnomalyModel v0:base.py:373 Test results saved to tests/assets/validation/ad_v0\nINFO     AnomalyModel v0:base.py:376 Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n\n&#34;}], &#34;tests/anomaly_detectors/anomalib_lmi/test_anomaly_model.py::test_cmds&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/anomaly_detectors/anomalib_lmi/test_anomaly_model.py::test_cmds&#34;, &#34;duration&#34;: &#34;00:01:60&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/anomaly_detectors/anomalib_lmi/test_anomaly_model.py::test_cmds&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:01:60&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;---------------------------- Captured stderr setup -----------------------------\nINFO:test_anomaly_model:Skipping adding root path to sys.path\n\n------------------------------ Captured log setup ------------------------------\nINFO     test_anomaly_model:test_anomaly_model.py:20 Skipping adding root path to sys.path\n\n----------------------------- Captured stderr call -----------------------------\nINFO:test_anomaly_model:running cmd: python -m anomalib_lmi.anomaly_model -i tests/assets/models/ad/model_v0.pt -d tests/assets/images/nvtec-ad -o /tmp/tmplmbi9tov -g -p\nINFO:test_anomaly_model:\nINFO:test_anomaly_model:/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.1 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\nINFO:AnomalyModel v0:Loading model: tests/assets/models/ad/model_v0.pt\nINFO:AnomalyModel v0:8 images from tests/assets/images/nvtec-ad\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/004-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/001-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/002-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/003-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/003-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/000-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/002-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/001-bad.png.\nINFO:AnomalyModel v0:Computing anomaly score PDF for all data.\nINFO:AnomalyModel v0:Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\nINFO:AnomalyModel v0:Anomaly patch threshold for 50% patch failure rate:7.933134044930409\nINFO:AnomalyModel v0:Anomaly max set to 97 percentile:42.51430235990022\nINFO:AnomalyModel v0:Min Proc Time: 0.023464679718017578\nINFO:AnomalyModel v0:Max Proc Time: 0.25834059715270996\nINFO:AnomalyModel v0:Avg Proc Time: 0.05386754870414734\nINFO:AnomalyModel v0:Median Proc Time: 0.024859309196472168\nINFO:AnomalyModel v0:Test results saved to /tmp/tmplmbi9tov\nINFO:AnomalyModel v0:Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n\nINFO:test_anomaly_model:running cmd: python -m anomalib_lmi.anomaly_model -a convert -i tests/assets/models/ad/model_v0.pt -e /tmp/tmplmbi9tov\nINFO:test_anomaly_model:&amp;amp;&amp;amp;&amp;amp;&amp;amp; RUNNING TensorRT.trtexec [TensorRT v8603] # trtexec --onnx=/tmp/tmplmbi9tov/model.onnx --saveEngine=/tmp/tmplmbi9tov/model.engine --memPoolSize=workspace:4096 --fp16\n[01/27/2025-20:29:26] [I] === Model Options ===\n[01/27/2025-20:29:26] [I] Format: ONNX\n[01/27/2025-20:29:26] [I] Model: /tmp/tmplmbi9tov/model.onnx\n[01/27/2025-20:29:26] [I] Output:\n[01/27/2025-20:29:26] [I] === Build Options ===\n[01/27/2025-20:29:26] [I] Max batch: explicit batch\n[01/27/2025-20:29:26] [I] Memory Pools: workspace: 4096 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default\n[01/27/2025-20:29:26] [I] minTiming: 1\n[01/27/2025-20:29:26] [I] avgTiming: 8\n[01/27/2025-20:29:26] [I] Precision: FP32+FP16\n[01/27/2025-20:29:26] [I] LayerPrecisions: \n[01/27/2025-20:29:26] [I] Layer Device Types: \n[01/27/2025-20:29:26] [I] Calibration: \n[01/27/2025-20:29:26] [I] Refit: Disabled\n[01/27/2025-20:29:26] [I] Version Compatible: Disabled\n[01/27/2025-20:29:26] [I] ONNX Native InstanceNorm: Disabled\n[01/27/2025-20:29:26] [I] TensorRT runtime: full\n[01/27/2025-20:29:26] [I] Lean DLL Path: \n[01/27/2025-20:29:26] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n[01/27/2025-20:29:26] [I] Exclude Lean Runtime: Disabled\n[01/27/2025-20:29:26] [I] Sparsity: Disabled\n[01/27/2025-20:29:26] [I] Safe mode: Disabled\n[01/27/2025-20:29:26] [I] Build DLA standalone loadable: Disabled\n[01/27/2025-20:29:26] [I] Allow GPU fallback for DLA: Disabled\n[01/27/2025-20:29:26] [I] DirectIO mode: Disabled\n[01/27/2025-20:29:26] [I] Restricted mode: Disabled\n[01/27/2025-20:29:26] [I] Skip inference: Disabled\n[01/27/2025-20:29:26] [I] Save engine: /tmp/tmplmbi9tov/model.engine\n[01/27/2025-20:29:26] [I] Load engine: \n[01/27/2025-20:29:26] [I] Profiling verbosity: 0\n[01/27/2025-20:29:26] [I] Tactic sources: Using default tactic sources\n[01/27/2025-20:29:26] [I] timingCacheMode: local\n[01/27/2025-20:29:26] [I] timingCacheFile: \n[01/27/2025-20:29:26] [I] Heuristic: Disabled\n[01/27/2025-20:29:26] [I] Preview Features: Use default preview flags.\n[01/27/2025-20:29:26] [I] MaxAuxStreams: -1\n[01/27/2025-20:29:26] [I] BuilderOptimizationLevel: -1\n[01/27/2025-20:29:26] [I] Input(s)s format: fp32:CHW\n[01/27/2025-20:29:26] [I] Output(s)s format: fp32:CHW\n[01/27/2025-20:29:26] [I] Input build shapes: model\n[01/27/2025-20:29:26] [I] Input calibration shapes: model\n[01/27/2025-20:29:26] [I] === System Options ===\n[01/27/2025-20:29:26] [I] Device: 0\n[01/27/2025-20:29:26] [I] DLACore: \n[01/27/2025-20:29:26] [I] Plugins:\n[01/27/2025-20:29:26] [I] setPluginsToSerialize:\n[01/27/2025-20:29:26] [I] dynamicPlugins:\n[01/27/2025-20:29:26] [I] ignoreParsedPluginLibs: 0\n[01/27/2025-20:29:26] [I] \n[01/27/2025-20:29:26] [I] === Inference Options ===\n[01/27/2025-20:29:26] [I] Batch: Explicit\n[01/27/2025-20:29:26] [I] Input inference shapes: model\n[01/27/2025-20:29:26] [I] Iterations: 10\n[01/27/2025-20:29:26] [I] Duration: 3s (+ 200ms warm up)\n[01/27/2025-20:29:26] [I] Sleep time: 0ms\n[01/27/2025-20:29:26] [I] Idle time: 0ms\n[01/27/2025-20:29:26] [I] Inference Streams: 1\n[01/27/2025-20:29:26] [I] ExposeDMA: Disabled\n[01/27/2025-20:29:26] [I] Data transfers: Enabled\n[01/27/2025-20:29:26] [I] Spin-wait: Disabled\n[01/27/2025-20:29:26] [I] Multithreading: Disabled\n[01/27/2025-20:29:26] [I] CUDA Graph: Disabled\n[01/27/2025-20:29:26] [I] Separate profiling: Disabled\n[01/27/2025-20:29:26] [I] Time Deserialize: Disabled\n[01/27/2025-20:29:26] [I] Time Refit: Disabled\n[01/27/2025-20:29:26] [I] NVTX verbosity: 0\n[01/27/2025-20:29:26] [I] Persistent Cache Ratio: 0\n[01/27/2025-20:29:26] [I] Inputs:\n[01/27/2025-20:29:26] [I] === Reporting Options ===\n[01/27/2025-20:29:26] [I] Verbose: Disabled\n[01/27/2025-20:29:26] [I] Averages: 10 inferences\n[01/27/2025-20:29:26] [I] Percentiles: 90,95,99\n[01/27/2025-20:29:26] [I] Dump refittable layers:Disabled\n[01/27/2025-20:29:26] [I] Dump output: Disabled\n[01/27/2025-20:29:26] [I] Profile: Disabled\n[01/27/2025-20:29:26] [I] Export timing to JSON file: \n[01/27/2025-20:29:26] [I] Export output to JSON file: \n[01/27/2025-20:29:26] [I] Export profile to JSON file: \n[01/27/2025-20:29:26] [I] \n[01/27/2025-20:29:26] [I] === Device Information ===\n[01/27/2025-20:29:26] [I] Selected Device: NVIDIA GeForce RTX 4070 Laptop GPU\n[01/27/2025-20:29:26] [I] Compute Capability: 8.9\n[01/27/2025-20:29:26] [I] SMs: 36\n[01/27/2025-20:29:26] [I] Device Global Memory: 7935 MiB\n[01/27/2025-20:29:26] [I] Shared Memory per SM: 100 KiB\n[01/27/2025-20:29:26] [I] Memory Bus Width: 128 bits (ECC disabled)\n[01/27/2025-20:29:26] [I] Application Compute Clock Rate: 1.23 GHz\n[01/27/2025-20:29:26] [I] Application Memory Clock Rate: 8.001 GHz\n[01/27/2025-20:29:26] [I] \n[01/27/2025-20:29:26] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n[01/27/2025-20:29:26] [I] \n[01/27/2025-20:29:26] [I] TensorRT version: 8.6.3\n[01/27/2025-20:29:26] [I] Loading standard plugins\n[01/27/2025-20:29:26] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 23, GPU 3394 (MiB)\n[01/27/2025-20:29:30] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1453, GPU +268, now: CPU 1552, GPU 3662 (MiB)\n[01/27/2025-20:29:30] [I] Start parsing network model.\n[01/27/2025-20:29:31] [I] [TRT] ----------------------------------------------------------------\n[01/27/2025-20:29:31] [I] [TRT] Input filename:   /tmp/tmplmbi9tov/model.onnx\n[01/27/2025-20:29:31] [I] [TRT] ONNX IR version:  0.0.7\n[01/27/2025-20:29:31] [I] [TRT] Opset version:    14\n[01/27/2025-20:29:31] [I] [TRT] Producer name:    pytorch\n[01/27/2025-20:29:31] [I] [TRT] Producer version: 2.3.0\n[01/27/2025-20:29:31] [I] [TRT] Domain:           \n[01/27/2025-20:29:31] [I] [TRT] Model version:    0\n[01/27/2025-20:29:31] [I] [TRT] Doc string:       \n[01/27/2025-20:29:31] [I] [TRT] ----------------------------------------------------------------\n[01/27/2025-20:29:31] [I] Finished parsing network model. Parse time: 0.642608\n[01/27/2025-20:29:31] [I] [TRT] Graph optimization time: 0.00962884 seconds.\n[01/27/2025-20:29:31] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n[01/27/2025-20:31:05] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n[01/27/2025-20:31:05] [I] [TRT] Total Host Persistent Memory: 89200\n[01/27/2025-20:31:05] [I] [TRT] Total Device Persistent Memory: 0\n[01/27/2025-20:31:05] [I] [TRT] Total Scratch Memory: 2515456\n[01/27/2025-20:31:05] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 245 MiB, GPU 496 MiB\n[01/27/2025-20:31:05] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 26 steps to complete.\n[01/27/2025-20:31:05] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.176441ms to assign 5 blocks to 26 nodes requiring 5425664 bytes.\n[01/27/2025-20:31:05] [I] [TRT] Total Activation Memory: 5425664\n[01/27/2025-20:31:05] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +5, GPU +246, now: CPU 5, GPU 246 (MiB)\n[01/27/2025-20:31:06] [I] Engine built in 99.6177 sec.\n[01/27/2025-20:31:06] [I] [TRT] Loaded engine size: 246 MiB\n[01/27/2025-20:31:06] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +245, now: CPU 0, GPU 245 (MiB)\n[01/27/2025-20:31:06] [I] Engine deserialized in 0.134949 sec.\n[01/27/2025-20:31:06] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +5, now: CPU 0, GPU 250 (MiB)\n[01/27/2025-20:31:06] [I] Setting persistentCacheLimit to 0 bytes.\n[01/27/2025-20:31:06] [I] Using random values for input input\n[01/27/2025-20:31:06] [I] Input binding for input with dimensions 1x3x224x224 is created.\n[01/27/2025-20:31:06] [I] Output binding for output with dimensions 1x1x224x224 is created.\n[01/27/2025-20:31:06] [I] Starting inference\n[01/27/2025-20:31:09] [I] Warmup completed 105 queries over 200 ms\n[01/27/2025-20:31:09] [I] Timing trace has 1565 queries over 3.00749 s\n[01/27/2025-20:31:09] [I] \n[01/27/2025-20:31:09] [I] === Trace details ===\n[01/27/2025-20:31:09] [I] Trace averages of 10 runs:\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.47819 ms - Host latency: 2.57253 ms (enqueue 0.462616 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.43732 ms - Host latency: 2.52912 ms (enqueue 0.425639 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.36338 ms - Host latency: 2.44678 ms (enqueue 0.385358 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.44061 ms - Host latency: 2.52846 ms (enqueue 0.36145 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.48463 ms - Host latency: 2.56498 ms (enqueue 0.228534 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.4407 ms - Host latency: 2.52079 ms (enqueue 0.232834 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.41981 ms - Host latency: 2.49836 ms (enqueue 0.251111 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.4233 ms - Host latency: 2.50651 ms (enqueue 0.366406 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.47931 ms - Host latency: 2.55778 ms (enqueue 0.194531 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.48791 ms - Host latency: 2.5737 ms (enqueue 0.402005 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.46999 ms - Host latency: 2.56301 ms (enqueue 0.404535 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.44019 ms - Host latency: 2.52943 ms (enqueue 0.36926 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.40548 ms - Host latency: 2.48345 ms (enqueue 0.235098 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.44019 ms - Host latency: 2.52038 ms (enqueue 0.265045 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.48925 ms - Host latency: 2.57218 ms (enqueue 0.331512 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.46466 ms - Host latency: 2.5569 ms (enqueue 0.545001 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.4403 ms - Host latency: 2.52872 ms (enqueue 0.501013 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.40056 ms - Host latency: 2.48069 ms (enqueue 0.215912 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.43303 ms - Host latency: 2.50972 ms (enqueue 0.190985 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.35735 ms - Host latency: 2.43747 ms (enqueue 0.238104 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.02762 ms - Host latency: 2.11783 ms (enqueue 0.411932 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.91858 ms - Host latency: 2.00825 ms (enqueue 0.333289 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.87496 ms - Host latency: 1.96882 ms (enqueue 0.465503 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84843 ms - Host latency: 1.94114 ms (enqueue 0.432709 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83789 ms - Host latency: 1.91923 ms (enqueue 0.326715 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83295 ms - Host latency: 1.91309 ms (enqueue 0.216718 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86634 ms - Host latency: 1.94457 ms (enqueue 0.168567 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8822 ms - Host latency: 1.96244 ms (enqueue 0.303442 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.88867 ms - Host latency: 1.96903 ms (enqueue 0.343488 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.88263 ms - Host latency: 1.96573 ms (enqueue 0.391577 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.89052 ms - Host latency: 1.96667 ms (enqueue 0.251386 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.89163 ms - Host latency: 1.97194 ms (enqueue 0.204437 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.88496 ms - Host latency: 1.96534 ms (enqueue 0.239514 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.88786 ms - Host latency: 1.96559 ms (enqueue 0.194318 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.88517 ms - Host latency: 1.96339 ms (enqueue 0.175714 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.89326 ms - Host latency: 1.97418 ms (enqueue 0.274011 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.89041 ms - Host latency: 1.96639 ms (enqueue 0.208618 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.87739 ms - Host latency: 1.9504 ms (enqueue 0.0807373 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.87371 ms - Host latency: 1.95576 ms (enqueue 0.211902 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86992 ms - Host latency: 1.94852 ms (enqueue 0.178918 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.855 ms - Host latency: 1.92821 ms (enqueue 0.072998 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84156 ms - Host latency: 1.91818 ms (enqueue 0.155737 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83462 ms - Host latency: 1.91895 ms (enqueue 0.165454 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82468 ms - Host latency: 1.90525 ms (enqueue 0.145239 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81985 ms - Host latency: 1.89805 ms (enqueue 0.205273 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81892 ms - Host latency: 1.89788 ms (enqueue 0.230981 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81904 ms - Host latency: 1.89801 ms (enqueue 0.241748 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81893 ms - Host latency: 1.89511 ms (enqueue 0.180835 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81945 ms - Host latency: 1.89458 ms (enqueue 0.222485 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81924 ms - Host latency: 1.89473 ms (enqueue 0.234387 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81895 ms - Host latency: 1.89919 ms (enqueue 0.274658 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81523 ms - Host latency: 1.89481 ms (enqueue 0.31001 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.80728 ms - Host latency: 1.88652 ms (enqueue 0.333081 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8125 ms - Host latency: 1.88812 ms (enqueue 0.196936 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81136 ms - Host latency: 1.88925 ms (enqueue 0.245312 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82856 ms - Host latency: 1.90836 ms (enqueue 0.247644 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81299 ms - Host latency: 1.89154 ms (enqueue 0.303796 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85261 ms - Host latency: 1.93484 ms (enqueue 0.189929 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82321 ms - Host latency: 1.90623 ms (enqueue 0.355554 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81943 ms - Host latency: 1.89985 ms (enqueue 0.32417 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82131 ms - Host latency: 1.89968 ms (enqueue 0.244861 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82079 ms - Host latency: 1.89829 ms (enqueue 0.202527 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81562 ms - Host latency: 1.89426 ms (enqueue 0.231262 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8045 ms - Host latency: 1.8802 ms (enqueue 0.222864 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.79619 ms - Host latency: 1.88328 ms (enqueue 0.39104 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.79108 ms - Host latency: 1.87074 ms (enqueue 0.257263 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.79191 ms - Host latency: 1.8767 ms (enqueue 0.343555 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.79733 ms - Host latency: 1.87987 ms (enqueue 0.272864 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81123 ms - Host latency: 1.88793 ms (enqueue 0.250134 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82322 ms - Host latency: 1.90017 ms (enqueue 0.235596 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83816 ms - Host latency: 1.91627 ms (enqueue 0.268091 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84445 ms - Host latency: 1.92603 ms (enqueue 0.408032 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84608 ms - Host latency: 1.93011 ms (enqueue 0.281189 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84698 ms - Host latency: 1.92474 ms (enqueue 0.233936 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84282 ms - Host latency: 1.92216 ms (enqueue 0.226868 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83143 ms - Host latency: 1.91 ms (enqueue 0.232788 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82263 ms - Host latency: 1.90242 ms (enqueue 0.232104 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83265 ms - Host latency: 1.91259 ms (enqueue 0.265942 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83286 ms - Host latency: 1.91321 ms (enqueue 0.262561 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83345 ms - Host latency: 1.91217 ms (enqueue 0.212012 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83275 ms - Host latency: 1.91262 ms (enqueue 0.258032 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83848 ms - Host latency: 1.9309 ms (enqueue 0.334729 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84001 ms - Host latency: 1.9184 ms (enqueue 0.243384 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84801 ms - Host latency: 1.93352 ms (enqueue 0.4078 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85476 ms - Host latency: 1.93585 ms (enqueue 0.279578 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85848 ms - Host latency: 1.9489 ms (enqueue 0.389148 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85457 ms - Host latency: 1.9351 ms (enqueue 0.258203 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85856 ms - Host latency: 1.93833 ms (enqueue 0.237805 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.87678 ms - Host latency: 1.95457 ms (enqueue 0.192761 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86963 ms - Host latency: 1.94648 ms (enqueue 0.162329 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86274 ms - Host latency: 1.93988 ms (enqueue 0.190527 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.87054 ms - Host latency: 1.95229 ms (enqueue 0.29353 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86263 ms - Host latency: 1.95684 ms (enqueue 0.393115 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86323 ms - Host latency: 1.93907 ms (enqueue 0.16991 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85505 ms - Host latency: 1.93269 ms (enqueue 0.213574 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84829 ms - Host latency: 1.9249 ms (enqueue 0.195215 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84141 ms - Host latency: 1.91814 ms (enqueue 0.234546 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83538 ms - Host latency: 1.91272 ms (enqueue 0.229492 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83296 ms - Host latency: 1.90828 ms (enqueue 0.235962 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83325 ms - Host latency: 1.9218 ms (enqueue 0.400708 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83357 ms - Host latency: 1.92595 ms (enqueue 0.427368 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83293 ms - Host latency: 1.91575 ms (enqueue 0.299487 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83191 ms - Host latency: 1.91001 ms (enqueue 0.252905 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82297 ms - Host latency: 1.91694 ms (enqueue 0.394897 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82402 ms - Host latency: 1.91453 ms (enqueue 0.366162 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83354 ms - Host latency: 1.91223 ms (enqueue 0.215015 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83367 ms - Host latency: 1.92417 ms (enqueue 0.387256 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82544 ms - Host latency: 1.91218 ms (enqueue 0.374536 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82886 ms - Host latency: 1.90854 ms (enqueue 0.272974 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82815 ms - Host latency: 1.91553 ms (enqueue 0.358154 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8218 ms - Host latency: 1.90759 ms (enqueue 0.320996 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82317 ms - Host latency: 1.93337 ms (enqueue 0.460278 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82012 ms - Host latency: 1.90413 ms (enqueue 0.327661 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81548 ms - Host latency: 1.88928 ms (enqueue 0.20061 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8158 ms - Host latency: 1.88936 ms (enqueue 0.175708 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81621 ms - Host latency: 1.89365 ms (enqueue 0.366211 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81638 ms - Host latency: 1.90129 ms (enqueue 0.471851 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81565 ms - Host latency: 1.90151 ms (enqueue 0.514014 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81648 ms - Host latency: 1.89861 ms (enqueue 0.375 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81587 ms - Host latency: 1.89463 ms (enqueue 0.286987 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81997 ms - Host latency: 1.91772 ms (enqueue 0.465649 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82866 ms - Host latency: 1.92285 ms (enqueue 0.455444 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83372 ms - Host latency: 1.92566 ms (enqueue 0.429663 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83245 ms - Host latency: 1.91641 ms (enqueue 0.274878 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8342 ms - Host latency: 1.92742 ms (enqueue 0.438013 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83281 ms - Host latency: 1.92781 ms (enqueue 0.406519 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83359 ms - Host latency: 1.92412 ms (enqueue 0.386206 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82339 ms - Host latency: 1.91201 ms (enqueue 0.330322 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83354 ms - Host latency: 1.91277 ms (enqueue 0.224609 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83298 ms - Host latency: 1.91179 ms (enqueue 0.275342 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8335 ms - Host latency: 1.91243 ms (enqueue 0.209082 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83333 ms - Host latency: 1.91047 ms (enqueue 0.24917 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83354 ms - Host latency: 1.92495 ms (enqueue 0.404834 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83325 ms - Host latency: 1.91514 ms (enqueue 0.289209 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83293 ms - Host latency: 1.91223 ms (enqueue 0.200146 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83577 ms - Host latency: 1.92539 ms (enqueue 0.400366 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8394 ms - Host latency: 1.92 ms (enqueue 0.327466 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84006 ms - Host latency: 1.91819 ms (enqueue 0.224512 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83992 ms - Host latency: 1.91479 ms (enqueue 0.14939 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84629 ms - Host latency: 1.92227 ms (enqueue 0.0747803 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84607 ms - Host latency: 1.92158 ms (enqueue 0.0792725 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85427 ms - Host latency: 1.93127 ms (enqueue 0.0760742 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85996 ms - Host latency: 1.93723 ms (enqueue 0.0970215 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85554 ms - Host latency: 1.93652 ms (enqueue 0.26084 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85439 ms - Host latency: 1.9302 ms (enqueue 0.213208 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85403 ms - Host latency: 1.93345 ms (enqueue 0.303296 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85425 ms - Host latency: 1.94255 ms (enqueue 0.527637 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.855 ms - Host latency: 1.94385 ms (enqueue 0.538379 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85198 ms - Host latency: 1.93696 ms (enqueue 0.363525 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84321 ms - Host latency: 1.92158 ms (enqueue 0.311768 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84124 ms - Host latency: 1.91875 ms (enqueue 0.263135 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84695 ms - Host latency: 1.92693 ms (enqueue 0.253101 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84685 ms - Host latency: 1.92683 ms (enqueue 0.291675 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83904 ms - Host latency: 1.91387 ms (enqueue 0.182446 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83347 ms - Host latency: 1.91394 ms (enqueue 0.367627 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83291 ms - Host latency: 1.9136 ms (enqueue 0.403125 ms)\n[01/27/2025-20:31:09] [I] \n[01/27/2025-20:31:09] [I] === Performance summary ===\n[01/27/2025-20:31:09] [I] Throughput: 520.368 qps\n[01/27/2025-20:31:09] [I] Latency: min = 1.86768 ms, max = 2.67358 ms, mean = 1.99947 ms, median = 1.92163 ms, percentile(90%) = 2.48682 ms, percentile(95%) = 2.5368 ms, percentile(99%) = 2.58585 ms\n[01/27/2025-20:31:09] [I] Enqueue Time: min = 0.0529785 ms, max = 0.928284 ms, mean = 0.287408 ms, median = 0.245361 ms, percentile(90%) = 0.479462 ms, percentile(95%) = 0.526794 ms, percentile(99%) = 0.685059 ms\n[01/27/2025-20:31:09] [I] H2D Latency: min = 0.052124 ms, max = 0.228516 ms, mean = 0.0622148 ms, median = 0.0598145 ms, percentile(90%) = 0.0740967 ms, percentile(95%) = 0.0752258 ms, percentile(99%) = 0.0849609 ms\n[01/27/2025-20:31:09] [I] GPU Compute Time: min = 1.78992 ms, max = 2.5979 ms, mean = 1.91749 ms, median = 1.83887 ms, percentile(90%) = 2.39722 ms, percentile(95%) = 2.44226 ms, percentile(99%) = 2.49036 ms\n[01/27/2025-20:31:09] [I] D2H Latency: min = 0.0185547 ms, max = 0.0311279 ms, mean = 0.0197571 ms, median = 0.0192871 ms, percentile(90%) = 0.0212402 ms, percentile(95%) = 0.0216064 ms, percentile(99%) = 0.0223389 ms\n[01/27/2025-20:31:09] [I] Total Host Walltime: 3.00749 s\n[01/27/2025-20:31:09] [I] Total GPU Compute Time: 3.00088 s\n[01/27/2025-20:31:09] [I] Explanations of the performance metrics are printed in the verbose logs.\n[01/27/2025-20:31:09] [I] \n&amp;amp;&amp;amp;&amp;amp;&amp;amp; PASSED TensorRT.trtexec [TensorRT v8603] # trtexec --onnx=/tmp/tmplmbi9tov/model.onnx --saveEngine=/tmp/tmplmbi9tov/model.engine --memPoolSize=workspace:4096 --fp16\n\nINFO:test_anomaly_model:/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.1 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\nINFO:AnomalyModel v0:Loading model: tests/assets/models/ad/model_v0.pt\nINFO:AnomalyModel v0:Converting pt to onnx...\n/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/jit_utils.py:307: UserWarning: Constant folding - Only steps=1 can be constant folded for opset &amp;gt;= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:702: UserWarning: Constant folding - Only steps=1 can be constant folded for opset &amp;gt;= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n  _C._jit_pass_onnx_graph_shape_type_inference(\n/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:1208: UserWarning: Constant folding - Only steps=1 can be constant folded for opset &amp;gt;= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n  _C._jit_pass_onnx_graph_shape_type_inference(\nINFO:AnomalyModel v0:the onnx model is saved at /tmp/tmplmbi9tov/model.onnx\nINFO:AnomalyModel v0:Converting onnx to trt engine...\n[01/27/2025-20:29:31] [W] [TRT] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n[01/27/2025-20:29:31] [W] [TRT] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\n[01/27/2025-20:31:05] [W] [TRT] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n[01/27/2025-20:31:05] [W] [TRT] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n[01/27/2025-20:31:05] [W] [TRT] Check verbose logs for the list of affected weights.\n[01/27/2025-20:31:05] [W] [TRT] - 19 weights are affected by this issue: Detected subnormal FP16 values.\n[01/27/2025-20:31:05] [W] [TRT] - 9 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n[01/27/2025-20:31:05] [W] [TRT] - 1 weights are affected by this issue: Detected finite FP32 values which would overflow in FP16 and converted them to the closest finite FP16 value.\n[01/27/2025-20:31:09] [W] * GPU compute time is unstable, with coefficient of variance = 10.5995%.\n[01/27/2025-20:31:09] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\ncp: &amp;#x27;/tmp/tmplmbi9tov/metadata.json&amp;#x27; and &amp;#x27;/tmp/tmplmbi9tov/metadata.json&amp;#x27; are the same file\n\n\n------------------------------ Captured log call -------------------------------\nINFO     test_anomaly_model:test_anomaly_model.py:50 running cmd: python -m anomalib_lmi.anomaly_model -i tests/assets/models/ad/model_v0.pt -d tests/assets/images/nvtec-ad -o /tmp/tmplmbi9tov -g -p\nINFO     test_anomaly_model:test_anomaly_model.py:52 \nINFO     test_anomaly_model:test_anomaly_model.py:53 /usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.1 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\nINFO:AnomalyModel v0:Loading model: tests/assets/models/ad/model_v0.pt\nINFO:AnomalyModel v0:8 images from tests/assets/images/nvtec-ad\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/004-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/001-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/002-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/003-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/003-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/000-bad.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/002-good.png.\nINFO:AnomalyModel v0:Processing image: tests/assets/images/nvtec-ad/001-bad.png.\nINFO:AnomalyModel v0:Computing anomaly score PDF for all data.\nINFO:AnomalyModel v0:Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\nINFO:AnomalyModel v0:Anomaly patch threshold for 50% patch failure rate:7.933134044930409\nINFO:AnomalyModel v0:Anomaly max set to 97 percentile:42.51430235990022\nINFO:AnomalyModel v0:Min Proc Time: 0.023464679718017578\nINFO:AnomalyModel v0:Max Proc Time: 0.25834059715270996\nINFO:AnomalyModel v0:Avg Proc Time: 0.05386754870414734\nINFO:AnomalyModel v0:Median Proc Time: 0.024859309196472168\nINFO:AnomalyModel v0:Test results saved to /tmp/tmplmbi9tov\nINFO:AnomalyModel v0:Threshold options:\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Threshold             |   2.95 |   7.54 |  12.1 |  16.7 |  21.3  | 25.9  | 30.5   | 35.1    | 39.7    | 44.3     |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Patch Defect  |  92.6  |  53.4  |  21.9 |   7.5 |   2.29 |  0.65 |  0.175 |  0.0451 |  0.0113 |  0.00276 |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n| Prob of Sample Defect | 100    | 100    | 100   | 100   | 100    | 62.5  | 62.5   | 25      | 25      |  0       |\n+-----------------------+--------+--------+-------+-------+--------+-------+--------+---------+---------+----------+\n\nINFO     test_anomaly_model:test_anomaly_model.py:56 running cmd: python -m anomalib_lmi.anomaly_model -a convert -i tests/assets/models/ad/model_v0.pt -e /tmp/tmplmbi9tov\nINFO     test_anomaly_model:test_anomaly_model.py:58 &amp;amp;&amp;amp;&amp;amp;&amp;amp; RUNNING TensorRT.trtexec [TensorRT v8603] # trtexec --onnx=/tmp/tmplmbi9tov/model.onnx --saveEngine=/tmp/tmplmbi9tov/model.engine --memPoolSize=workspace:4096 --fp16\n[01/27/2025-20:29:26] [I] === Model Options ===\n[01/27/2025-20:29:26] [I] Format: ONNX\n[01/27/2025-20:29:26] [I] Model: /tmp/tmplmbi9tov/model.onnx\n[01/27/2025-20:29:26] [I] Output:\n[01/27/2025-20:29:26] [I] === Build Options ===\n[01/27/2025-20:29:26] [I] Max batch: explicit batch\n[01/27/2025-20:29:26] [I] Memory Pools: workspace: 4096 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default\n[01/27/2025-20:29:26] [I] minTiming: 1\n[01/27/2025-20:29:26] [I] avgTiming: 8\n[01/27/2025-20:29:26] [I] Precision: FP32+FP16\n[01/27/2025-20:29:26] [I] LayerPrecisions: \n[01/27/2025-20:29:26] [I] Layer Device Types: \n[01/27/2025-20:29:26] [I] Calibration: \n[01/27/2025-20:29:26] [I] Refit: Disabled\n[01/27/2025-20:29:26] [I] Version Compatible: Disabled\n[01/27/2025-20:29:26] [I] ONNX Native InstanceNorm: Disabled\n[01/27/2025-20:29:26] [I] TensorRT runtime: full\n[01/27/2025-20:29:26] [I] Lean DLL Path: \n[01/27/2025-20:29:26] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n[01/27/2025-20:29:26] [I] Exclude Lean Runtime: Disabled\n[01/27/2025-20:29:26] [I] Sparsity: Disabled\n[01/27/2025-20:29:26] [I] Safe mode: Disabled\n[01/27/2025-20:29:26] [I] Build DLA standalone loadable: Disabled\n[01/27/2025-20:29:26] [I] Allow GPU fallback for DLA: Disabled\n[01/27/2025-20:29:26] [I] DirectIO mode: Disabled\n[01/27/2025-20:29:26] [I] Restricted mode: Disabled\n[01/27/2025-20:29:26] [I] Skip inference: Disabled\n[01/27/2025-20:29:26] [I] Save engine: /tmp/tmplmbi9tov/model.engine\n[01/27/2025-20:29:26] [I] Load engine: \n[01/27/2025-20:29:26] [I] Profiling verbosity: 0\n[01/27/2025-20:29:26] [I] Tactic sources: Using default tactic sources\n[01/27/2025-20:29:26] [I] timingCacheMode: local\n[01/27/2025-20:29:26] [I] timingCacheFile: \n[01/27/2025-20:29:26] [I] Heuristic: Disabled\n[01/27/2025-20:29:26] [I] Preview Features: Use default preview flags.\n[01/27/2025-20:29:26] [I] MaxAuxStreams: -1\n[01/27/2025-20:29:26] [I] BuilderOptimizationLevel: -1\n[01/27/2025-20:29:26] [I] Input(s)s format: fp32:CHW\n[01/27/2025-20:29:26] [I] Output(s)s format: fp32:CHW\n[01/27/2025-20:29:26] [I] Input build shapes: model\n[01/27/2025-20:29:26] [I] Input calibration shapes: model\n[01/27/2025-20:29:26] [I] === System Options ===\n[01/27/2025-20:29:26] [I] Device: 0\n[01/27/2025-20:29:26] [I] DLACore: \n[01/27/2025-20:29:26] [I] Plugins:\n[01/27/2025-20:29:26] [I] setPluginsToSerialize:\n[01/27/2025-20:29:26] [I] dynamicPlugins:\n[01/27/2025-20:29:26] [I] ignoreParsedPluginLibs: 0\n[01/27/2025-20:29:26] [I] \n[01/27/2025-20:29:26] [I] === Inference Options ===\n[01/27/2025-20:29:26] [I] Batch: Explicit\n[01/27/2025-20:29:26] [I] Input inference shapes: model\n[01/27/2025-20:29:26] [I] Iterations: 10\n[01/27/2025-20:29:26] [I] Duration: 3s (+ 200ms warm up)\n[01/27/2025-20:29:26] [I] Sleep time: 0ms\n[01/27/2025-20:29:26] [I] Idle time: 0ms\n[01/27/2025-20:29:26] [I] Inference Streams: 1\n[01/27/2025-20:29:26] [I] ExposeDMA: Disabled\n[01/27/2025-20:29:26] [I] Data transfers: Enabled\n[01/27/2025-20:29:26] [I] Spin-wait: Disabled\n[01/27/2025-20:29:26] [I] Multithreading: Disabled\n[01/27/2025-20:29:26] [I] CUDA Graph: Disabled\n[01/27/2025-20:29:26] [I] Separate profiling: Disabled\n[01/27/2025-20:29:26] [I] Time Deserialize: Disabled\n[01/27/2025-20:29:26] [I] Time Refit: Disabled\n[01/27/2025-20:29:26] [I] NVTX verbosity: 0\n[01/27/2025-20:29:26] [I] Persistent Cache Ratio: 0\n[01/27/2025-20:29:26] [I] Inputs:\n[01/27/2025-20:29:26] [I] === Reporting Options ===\n[01/27/2025-20:29:26] [I] Verbose: Disabled\n[01/27/2025-20:29:26] [I] Averages: 10 inferences\n[01/27/2025-20:29:26] [I] Percentiles: 90,95,99\n[01/27/2025-20:29:26] [I] Dump refittable layers:Disabled\n[01/27/2025-20:29:26] [I] Dump output: Disabled\n[01/27/2025-20:29:26] [I] Profile: Disabled\n[01/27/2025-20:29:26] [I] Export timing to JSON file: \n[01/27/2025-20:29:26] [I] Export output to JSON file: \n[01/27/2025-20:29:26] [I] Export profile to JSON file: \n[01/27/2025-20:29:26] [I] \n[01/27/2025-20:29:26] [I] === Device Information ===\n[01/27/2025-20:29:26] [I] Selected Device: NVIDIA GeForce RTX 4070 Laptop GPU\n[01/27/2025-20:29:26] [I] Compute Capability: 8.9\n[01/27/2025-20:29:26] [I] SMs: 36\n[01/27/2025-20:29:26] [I] Device Global Memory: 7935 MiB\n[01/27/2025-20:29:26] [I] Shared Memory per SM: 100 KiB\n[01/27/2025-20:29:26] [I] Memory Bus Width: 128 bits (ECC disabled)\n[01/27/2025-20:29:26] [I] Application Compute Clock Rate: 1.23 GHz\n[01/27/2025-20:29:26] [I] Application Memory Clock Rate: 8.001 GHz\n[01/27/2025-20:29:26] [I] \n[01/27/2025-20:29:26] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n[01/27/2025-20:29:26] [I] \n[01/27/2025-20:29:26] [I] TensorRT version: 8.6.3\n[01/27/2025-20:29:26] [I] Loading standard plugins\n[01/27/2025-20:29:26] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 23, GPU 3394 (MiB)\n[01/27/2025-20:29:30] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1453, GPU +268, now: CPU 1552, GPU 3662 (MiB)\n[01/27/2025-20:29:30] [I] Start parsing network model.\n[01/27/2025-20:29:31] [I] [TRT] ----------------------------------------------------------------\n[01/27/2025-20:29:31] [I] [TRT] Input filename:   /tmp/tmplmbi9tov/model.onnx\n[01/27/2025-20:29:31] [I] [TRT] ONNX IR version:  0.0.7\n[01/27/2025-20:29:31] [I] [TRT] Opset version:    14\n[01/27/2025-20:29:31] [I] [TRT] Producer name:    pytorch\n[01/27/2025-20:29:31] [I] [TRT] Producer version: 2.3.0\n[01/27/2025-20:29:31] [I] [TRT] Domain:           \n[01/27/2025-20:29:31] [I] [TRT] Model version:    0\n[01/27/2025-20:29:31] [I] [TRT] Doc string:       \n[01/27/2025-20:29:31] [I] [TRT] ----------------------------------------------------------------\n[01/27/2025-20:29:31] [I] Finished parsing network model. Parse time: 0.642608\n[01/27/2025-20:29:31] [I] [TRT] Graph optimization time: 0.00962884 seconds.\n[01/27/2025-20:29:31] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n[01/27/2025-20:31:05] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n[01/27/2025-20:31:05] [I] [TRT] Total Host Persistent Memory: 89200\n[01/27/2025-20:31:05] [I] [TRT] Total Device Persistent Memory: 0\n[01/27/2025-20:31:05] [I] [TRT] Total Scratch Memory: 2515456\n[01/27/2025-20:31:05] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 245 MiB, GPU 496 MiB\n[01/27/2025-20:31:05] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 26 steps to complete.\n[01/27/2025-20:31:05] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.176441ms to assign 5 blocks to 26 nodes requiring 5425664 bytes.\n[01/27/2025-20:31:05] [I] [TRT] Total Activation Memory: 5425664\n[01/27/2025-20:31:05] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +5, GPU +246, now: CPU 5, GPU 246 (MiB)\n[01/27/2025-20:31:06] [I] Engine built in 99.6177 sec.\n[01/27/2025-20:31:06] [I] [TRT] Loaded engine size: 246 MiB\n[01/27/2025-20:31:06] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +245, now: CPU 0, GPU 245 (MiB)\n[01/27/2025-20:31:06] [I] Engine deserialized in 0.134949 sec.\n[01/27/2025-20:31:06] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +5, now: CPU 0, GPU 250 (MiB)\n[01/27/2025-20:31:06] [I] Setting persistentCacheLimit to 0 bytes.\n[01/27/2025-20:31:06] [I] Using random values for input input\n[01/27/2025-20:31:06] [I] Input binding for input with dimensions 1x3x224x224 is created.\n[01/27/2025-20:31:06] [I] Output binding for output with dimensions 1x1x224x224 is created.\n[01/27/2025-20:31:06] [I] Starting inference\n[01/27/2025-20:31:09] [I] Warmup completed 105 queries over 200 ms\n[01/27/2025-20:31:09] [I] Timing trace has 1565 queries over 3.00749 s\n[01/27/2025-20:31:09] [I] \n[01/27/2025-20:31:09] [I] === Trace details ===\n[01/27/2025-20:31:09] [I] Trace averages of 10 runs:\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.47819 ms - Host latency: 2.57253 ms (enqueue 0.462616 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.43732 ms - Host latency: 2.52912 ms (enqueue 0.425639 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.36338 ms - Host latency: 2.44678 ms (enqueue 0.385358 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.44061 ms - Host latency: 2.52846 ms (enqueue 0.36145 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.48463 ms - Host latency: 2.56498 ms (enqueue 0.228534 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.4407 ms - Host latency: 2.52079 ms (enqueue 0.232834 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.41981 ms - Host latency: 2.49836 ms (enqueue 0.251111 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.4233 ms - Host latency: 2.50651 ms (enqueue 0.366406 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.47931 ms - Host latency: 2.55778 ms (enqueue 0.194531 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.48791 ms - Host latency: 2.5737 ms (enqueue 0.402005 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.46999 ms - Host latency: 2.56301 ms (enqueue 0.404535 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.44019 ms - Host latency: 2.52943 ms (enqueue 0.36926 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.40548 ms - Host latency: 2.48345 ms (enqueue 0.235098 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.44019 ms - Host latency: 2.52038 ms (enqueue 0.265045 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.48925 ms - Host latency: 2.57218 ms (enqueue 0.331512 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.46466 ms - Host latency: 2.5569 ms (enqueue 0.545001 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.4403 ms - Host latency: 2.52872 ms (enqueue 0.501013 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.40056 ms - Host latency: 2.48069 ms (enqueue 0.215912 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.43303 ms - Host latency: 2.50972 ms (enqueue 0.190985 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.35735 ms - Host latency: 2.43747 ms (enqueue 0.238104 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 2.02762 ms - Host latency: 2.11783 ms (enqueue 0.411932 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.91858 ms - Host latency: 2.00825 ms (enqueue 0.333289 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.87496 ms - Host latency: 1.96882 ms (enqueue 0.465503 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84843 ms - Host latency: 1.94114 ms (enqueue 0.432709 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83789 ms - Host latency: 1.91923 ms (enqueue 0.326715 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83295 ms - Host latency: 1.91309 ms (enqueue 0.216718 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86634 ms - Host latency: 1.94457 ms (enqueue 0.168567 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8822 ms - Host latency: 1.96244 ms (enqueue 0.303442 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.88867 ms - Host latency: 1.96903 ms (enqueue 0.343488 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.88263 ms - Host latency: 1.96573 ms (enqueue 0.391577 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.89052 ms - Host latency: 1.96667 ms (enqueue 0.251386 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.89163 ms - Host latency: 1.97194 ms (enqueue 0.204437 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.88496 ms - Host latency: 1.96534 ms (enqueue 0.239514 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.88786 ms - Host latency: 1.96559 ms (enqueue 0.194318 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.88517 ms - Host latency: 1.96339 ms (enqueue 0.175714 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.89326 ms - Host latency: 1.97418 ms (enqueue 0.274011 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.89041 ms - Host latency: 1.96639 ms (enqueue 0.208618 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.87739 ms - Host latency: 1.9504 ms (enqueue 0.0807373 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.87371 ms - Host latency: 1.95576 ms (enqueue 0.211902 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86992 ms - Host latency: 1.94852 ms (enqueue 0.178918 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.855 ms - Host latency: 1.92821 ms (enqueue 0.072998 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84156 ms - Host latency: 1.91818 ms (enqueue 0.155737 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83462 ms - Host latency: 1.91895 ms (enqueue 0.165454 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82468 ms - Host latency: 1.90525 ms (enqueue 0.145239 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81985 ms - Host latency: 1.89805 ms (enqueue 0.205273 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81892 ms - Host latency: 1.89788 ms (enqueue 0.230981 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81904 ms - Host latency: 1.89801 ms (enqueue 0.241748 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81893 ms - Host latency: 1.89511 ms (enqueue 0.180835 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81945 ms - Host latency: 1.89458 ms (enqueue 0.222485 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81924 ms - Host latency: 1.89473 ms (enqueue 0.234387 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81895 ms - Host latency: 1.89919 ms (enqueue 0.274658 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81523 ms - Host latency: 1.89481 ms (enqueue 0.31001 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.80728 ms - Host latency: 1.88652 ms (enqueue 0.333081 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8125 ms - Host latency: 1.88812 ms (enqueue 0.196936 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81136 ms - Host latency: 1.88925 ms (enqueue 0.245312 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82856 ms - Host latency: 1.90836 ms (enqueue 0.247644 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81299 ms - Host latency: 1.89154 ms (enqueue 0.303796 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85261 ms - Host latency: 1.93484 ms (enqueue 0.189929 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82321 ms - Host latency: 1.90623 ms (enqueue 0.355554 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81943 ms - Host latency: 1.89985 ms (enqueue 0.32417 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82131 ms - Host latency: 1.89968 ms (enqueue 0.244861 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82079 ms - Host latency: 1.89829 ms (enqueue 0.202527 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81562 ms - Host latency: 1.89426 ms (enqueue 0.231262 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8045 ms - Host latency: 1.8802 ms (enqueue 0.222864 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.79619 ms - Host latency: 1.88328 ms (enqueue 0.39104 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.79108 ms - Host latency: 1.87074 ms (enqueue 0.257263 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.79191 ms - Host latency: 1.8767 ms (enqueue 0.343555 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.79733 ms - Host latency: 1.87987 ms (enqueue 0.272864 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81123 ms - Host latency: 1.88793 ms (enqueue 0.250134 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82322 ms - Host latency: 1.90017 ms (enqueue 0.235596 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83816 ms - Host latency: 1.91627 ms (enqueue 0.268091 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84445 ms - Host latency: 1.92603 ms (enqueue 0.408032 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84608 ms - Host latency: 1.93011 ms (enqueue 0.281189 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84698 ms - Host latency: 1.92474 ms (enqueue 0.233936 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84282 ms - Host latency: 1.92216 ms (enqueue 0.226868 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83143 ms - Host latency: 1.91 ms (enqueue 0.232788 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82263 ms - Host latency: 1.90242 ms (enqueue 0.232104 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83265 ms - Host latency: 1.91259 ms (enqueue 0.265942 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83286 ms - Host latency: 1.91321 ms (enqueue 0.262561 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83345 ms - Host latency: 1.91217 ms (enqueue 0.212012 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83275 ms - Host latency: 1.91262 ms (enqueue 0.258032 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83848 ms - Host latency: 1.9309 ms (enqueue 0.334729 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84001 ms - Host latency: 1.9184 ms (enqueue 0.243384 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84801 ms - Host latency: 1.93352 ms (enqueue 0.4078 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85476 ms - Host latency: 1.93585 ms (enqueue 0.279578 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85848 ms - Host latency: 1.9489 ms (enqueue 0.389148 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85457 ms - Host latency: 1.9351 ms (enqueue 0.258203 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85856 ms - Host latency: 1.93833 ms (enqueue 0.237805 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.87678 ms - Host latency: 1.95457 ms (enqueue 0.192761 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86963 ms - Host latency: 1.94648 ms (enqueue 0.162329 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86274 ms - Host latency: 1.93988 ms (enqueue 0.190527 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.87054 ms - Host latency: 1.95229 ms (enqueue 0.29353 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86263 ms - Host latency: 1.95684 ms (enqueue 0.393115 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.86323 ms - Host latency: 1.93907 ms (enqueue 0.16991 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85505 ms - Host latency: 1.93269 ms (enqueue 0.213574 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84829 ms - Host latency: 1.9249 ms (enqueue 0.195215 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84141 ms - Host latency: 1.91814 ms (enqueue 0.234546 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83538 ms - Host latency: 1.91272 ms (enqueue 0.229492 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83296 ms - Host latency: 1.90828 ms (enqueue 0.235962 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83325 ms - Host latency: 1.9218 ms (enqueue 0.400708 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83357 ms - Host latency: 1.92595 ms (enqueue 0.427368 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83293 ms - Host latency: 1.91575 ms (enqueue 0.299487 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83191 ms - Host latency: 1.91001 ms (enqueue 0.252905 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82297 ms - Host latency: 1.91694 ms (enqueue 0.394897 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82402 ms - Host latency: 1.91453 ms (enqueue 0.366162 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83354 ms - Host latency: 1.91223 ms (enqueue 0.215015 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83367 ms - Host latency: 1.92417 ms (enqueue 0.387256 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82544 ms - Host latency: 1.91218 ms (enqueue 0.374536 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82886 ms - Host latency: 1.90854 ms (enqueue 0.272974 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82815 ms - Host latency: 1.91553 ms (enqueue 0.358154 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8218 ms - Host latency: 1.90759 ms (enqueue 0.320996 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82317 ms - Host latency: 1.93337 ms (enqueue 0.460278 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82012 ms - Host latency: 1.90413 ms (enqueue 0.327661 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81548 ms - Host latency: 1.88928 ms (enqueue 0.20061 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8158 ms - Host latency: 1.88936 ms (enqueue 0.175708 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81621 ms - Host latency: 1.89365 ms (enqueue 0.366211 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81638 ms - Host latency: 1.90129 ms (enqueue 0.471851 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81565 ms - Host latency: 1.90151 ms (enqueue 0.514014 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81648 ms - Host latency: 1.89861 ms (enqueue 0.375 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81587 ms - Host latency: 1.89463 ms (enqueue 0.286987 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.81997 ms - Host latency: 1.91772 ms (enqueue 0.465649 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82866 ms - Host latency: 1.92285 ms (enqueue 0.455444 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83372 ms - Host latency: 1.92566 ms (enqueue 0.429663 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83245 ms - Host latency: 1.91641 ms (enqueue 0.274878 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8342 ms - Host latency: 1.92742 ms (enqueue 0.438013 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83281 ms - Host latency: 1.92781 ms (enqueue 0.406519 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83359 ms - Host latency: 1.92412 ms (enqueue 0.386206 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.82339 ms - Host latency: 1.91201 ms (enqueue 0.330322 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83354 ms - Host latency: 1.91277 ms (enqueue 0.224609 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83298 ms - Host latency: 1.91179 ms (enqueue 0.275342 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8335 ms - Host latency: 1.91243 ms (enqueue 0.209082 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83333 ms - Host latency: 1.91047 ms (enqueue 0.24917 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83354 ms - Host latency: 1.92495 ms (enqueue 0.404834 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83325 ms - Host latency: 1.91514 ms (enqueue 0.289209 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83293 ms - Host latency: 1.91223 ms (enqueue 0.200146 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83577 ms - Host latency: 1.92539 ms (enqueue 0.400366 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.8394 ms - Host latency: 1.92 ms (enqueue 0.327466 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84006 ms - Host latency: 1.91819 ms (enqueue 0.224512 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83992 ms - Host latency: 1.91479 ms (enqueue 0.14939 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84629 ms - Host latency: 1.92227 ms (enqueue 0.0747803 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84607 ms - Host latency: 1.92158 ms (enqueue 0.0792725 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85427 ms - Host latency: 1.93127 ms (enqueue 0.0760742 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85996 ms - Host latency: 1.93723 ms (enqueue 0.0970215 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85554 ms - Host latency: 1.93652 ms (enqueue 0.26084 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85439 ms - Host latency: 1.9302 ms (enqueue 0.213208 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85403 ms - Host latency: 1.93345 ms (enqueue 0.303296 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85425 ms - Host latency: 1.94255 ms (enqueue 0.527637 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.855 ms - Host latency: 1.94385 ms (enqueue 0.538379 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.85198 ms - Host latency: 1.93696 ms (enqueue 0.363525 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84321 ms - Host latency: 1.92158 ms (enqueue 0.311768 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84124 ms - Host latency: 1.91875 ms (enqueue 0.263135 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84695 ms - Host latency: 1.92693 ms (enqueue 0.253101 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.84685 ms - Host latency: 1.92683 ms (enqueue 0.291675 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83904 ms - Host latency: 1.91387 ms (enqueue 0.182446 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83347 ms - Host latency: 1.91394 ms (enqueue 0.367627 ms)\n[01/27/2025-20:31:09] [I] Average on 10 runs - GPU latency: 1.83291 ms - Host latency: 1.9136 ms (enqueue 0.403125 ms)\n[01/27/2025-20:31:09] [I] \n[01/27/2025-20:31:09] [I] === Performance summary ===\n[01/27/2025-20:31:09] [I] Throughput: 520.368 qps\n[01/27/2025-20:31:09] [I] Latency: min = 1.86768 ms, max = 2.67358 ms, mean = 1.99947 ms, median = 1.92163 ms, percentile(90%) = 2.48682 ms, percentile(95%) = 2.5368 ms, percentile(99%) = 2.58585 ms\n[01/27/2025-20:31:09] [I] Enqueue Time: min = 0.0529785 ms, max = 0.928284 ms, mean = 0.287408 ms, median = 0.245361 ms, percentile(90%) = 0.479462 ms, percentile(95%) = 0.526794 ms, percentile(99%) = 0.685059 ms\n[01/27/2025-20:31:09] [I] H2D Latency: min = 0.052124 ms, max = 0.228516 ms, mean = 0.0622148 ms, median = 0.0598145 ms, percentile(90%) = 0.0740967 ms, percentile(95%) = 0.0752258 ms, percentile(99%) = 0.0849609 ms\n[01/27/2025-20:31:09] [I] GPU Compute Time: min = 1.78992 ms, max = 2.5979 ms, mean = 1.91749 ms, median = 1.83887 ms, percentile(90%) = 2.39722 ms, percentile(95%) = 2.44226 ms, percentile(99%) = 2.49036 ms\n[01/27/2025-20:31:09] [I] D2H Latency: min = 0.0185547 ms, max = 0.0311279 ms, mean = 0.0197571 ms, median = 0.0192871 ms, percentile(90%) = 0.0212402 ms, percentile(95%) = 0.0216064 ms, percentile(99%) = 0.0223389 ms\n[01/27/2025-20:31:09] [I] Total Host Walltime: 3.00749 s\n[01/27/2025-20:31:09] [I] Total GPU Compute Time: 3.00088 s\n[01/27/2025-20:31:09] [I] Explanations of the performance metrics are printed in the verbose logs.\n[01/27/2025-20:31:09] [I] \n&amp;amp;&amp;amp;&amp;amp;&amp;amp; PASSED TensorRT.trtexec [TensorRT v8603] # trtexec --onnx=/tmp/tmplmbi9tov/model.onnx --saveEngine=/tmp/tmplmbi9tov/model.engine --memPoolSize=workspace:4096 --fp16\n\nINFO     test_anomaly_model:test_anomaly_model.py:59 /usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.1 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\nINFO:AnomalyModel v0:Loading model: tests/assets/models/ad/model_v0.pt\nINFO:AnomalyModel v0:Converting pt to onnx...\n/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/jit_utils.py:307: UserWarning: Constant folding - Only steps=1 can be constant folded for opset &amp;gt;= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:702: UserWarning: Constant folding - Only steps=1 can be constant folded for opset &amp;gt;= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n  _C._jit_pass_onnx_graph_shape_type_inference(\n/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:1208: UserWarning: Constant folding - Only steps=1 can be constant folded for opset &amp;gt;= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n  _C._jit_pass_onnx_graph_shape_type_inference(\nINFO:AnomalyModel v0:the onnx model is saved at /tmp/tmplmbi9tov/model.onnx\nINFO:AnomalyModel v0:Converting onnx to trt engine...\n[01/27/2025-20:29:31] [W] [TRT] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n[01/27/2025-20:29:31] [W] [TRT] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\n[01/27/2025-20:31:05] [W] [TRT] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n[01/27/2025-20:31:05] [W] [TRT] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n[01/27/2025-20:31:05] [W] [TRT] Check verbose logs for the list of affected weights.\n[01/27/2025-20:31:05] [W] [TRT] - 19 weights are affected by this issue: Detected subnormal FP16 values.\n[01/27/2025-20:31:05] [W] [TRT] - 9 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n[01/27/2025-20:31:05] [W] [TRT] - 1 weights are affected by this issue: Detected finite FP32 values which would overflow in FP16 and converted them to the closest finite FP16 value.\n[01/27/2025-20:31:09] [W] * GPU compute time is unstable, with coefficient of variance = 10.5995%.\n[01/27/2025-20:31:09] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\ncp: &amp;#x27;/tmp/tmplmbi9tov/metadata.json&amp;#x27; and &amp;#x27;/tmp/tmplmbi9tov/metadata.json&amp;#x27; are the same file\n\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;anomaly_detectors_v0_packaged.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
</html>